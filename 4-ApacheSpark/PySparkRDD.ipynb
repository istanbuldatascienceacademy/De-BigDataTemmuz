{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4791852d-806f-4031-baae-5be733acbc4a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### lambda fonksiyonu nedir?\n",
    "- lambda fonksiyonu normal bir fonksiyon gibi çalışır.\n",
    "- lambda fonksiyonu tek satırda yazılır.\n",
    "- lambda fonksiyonu bir değişkene atanabilir.\n",
    "- lambda fonksiyonu bir fonksiyonun içinde kullanılabilir.\n",
    "- lambda fonksiyonu bir fonksiyonun çıktısı olabilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeb99198-0af4-452f-8c95-b21bfdece709",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'YUSUF'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def deneme(isim):\n",
    "  return isim.upper()\n",
    "deneme(\"yusuf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3fc35d3-cf1f-455c-ba88-04908952deac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'YUSUF'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deneme1 = lambda isim: isim.upper()\n",
    "deneme1(\"yusuf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "805d5d67-8493-42fd-b5ef-72682f401814",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'YUSUF GZB'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def deneme(isim,soyisim):\n",
    "    return isim.upper() +\" \"+ soyisim.upper()\n",
    "deneme(\"yusuf\",\"gzb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91c390b6-91c8-4b7a-889f-7f6f728d9f75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'YUSUF GZB'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deneme1 = lambda isim,soyisim: isim.upper() +\" \"+ soyisim.upper()\n",
    "deneme1(\"yusuf\",\"gzb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f71820d-1b41-47f5-a33e-1978e232e358",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "map() fonksiyonu, Python'da bir iterable (örneğin, liste) üzerinde belirtilen bir fonksiyonu her elemana uygulayan ve sonuçları yeni bir iterable olarak döndüren bir fonksiyondur. \n",
    "\n",
    "Bu, özellikle lambda ifadeleri ile birlikte kullanıldığında güçlü bir araçtır\n",
    "\n",
    "```python\n",
    "# map() fonksiyonu örneği\n",
    "map(function, iterable, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ddd848-b63f-4dfe-ab6b-c148d2713399",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<map object at 0x7f870c56f970>\n<class 'map'>\n[1, 4, 9, 16, 25, 36]\n"
     ]
    }
   ],
   "source": [
    "numbers = [1,2,3,4,5,6]\n",
    "\n",
    "kare_al = map(lambda x: x**2,numbers)\n",
    "print(kare_al)\n",
    "print(type(kare_al))\n",
    "result_list = list(kare_al)\n",
    "print(result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5322ef62-3819-422c-bc07-faef504627f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 8, 6, 10, 13, 15]\n[6, 8, 6, 10, 13, 15]\n"
     ]
    }
   ],
   "source": [
    "numbers1 = [1,2,3,4,5,6]\n",
    "numbers2 = [5,6,3,6,8,9]\n",
    "\n",
    "def sum_lists(x,y):\n",
    "    return x+y\n",
    "\n",
    "sum_list_def = map(sum_lists,numbers1,numbers2)\n",
    "result_list = list(sum_list_def)\n",
    "print(result_list)\n",
    "\n",
    "sum_list_lam = list(map(lambda x,y:x+y,numbers1,numbers2))\n",
    "print(sum_list_lam)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8453f5b3-3efb-4dd3-badd-fe58505e0224",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### filter() fonksiyonu\n",
    "filter() fonksiyonu, bir iterable'daki her öğe için bir koşul belirten bir fonksiyon alır ve yalnızca koşulu karşılayan öğeleri içeren bir iterable döndürür.\n",
    "\n",
    "```python\n",
    "# filter() fonksiyonu örneği\n",
    "filter(function, iterable)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfa7f963-af10-4bf7-b546-ba3bf0c59700",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'clock', 'banana']\n"
     ]
    }
   ],
   "source": [
    "# Kelime Uzunluğu 5 veya Daha Fazla Olanları Filtreleme:\n",
    "words = [\"apple\", \"swim\", \"clock\", \"me\", \"kiwi\", \"banana\"]\n",
    "# def filtered_words(x):\n",
    "#     return len(x) >= 5\n",
    "# isim = \"yusuf\"\n",
    "# filtered_words(isim)\n",
    "\n",
    "filtered_words = list(filter(lambda x: len(x) >= 5, words))\n",
    "print(filtered_words) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3b117d0-4be5-4795-ae6d-e2a618422003",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Spark RDD\n",
    "- Spark, büyük veri işleme için hızlı ve genel amaçlı bir küme hesaplama sistemi sağlar.\n",
    "- RDD (Resilient Distributed Dataset) Spark'ın temel veri yapısıdır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ff2086e-ca49-459e-9dbd-d4a3073c5d8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=1947947839545222#setting/sparkui/0806-172203-xvdkktso/driver-4240339204871682127\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8726fb3290>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"ParallelizeExample\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9564eba3-72c1-4981-9bb9-7b64160d0cd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 5, 7, 9]\n<class 'pyspark.core.rdd.RDD'>\n[8, 1, 9, 2, 10, 3, 4, 5, 6, 7]\n[2, 4, 6, 8, 10, 12, 14, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 5, 7, 9]\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14]\nrdd4: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 2, 6, 10, 14, 18]\nrdd5: [2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,1,3,5,7,9]\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "print(rdd.collect())\n",
    "print(type(rdd))\n",
    "\n",
    "# distinc fonksiyonu ile tekrar eden elemanları silme\n",
    "# deneme = rdd.distinct()\n",
    "print(rdd.distinct().collect())\n",
    "\n",
    "\n",
    "# union fonksiyonu ile iki rdd birleştirme\n",
    "data2 = [2,4,6,8,10,12,14]\n",
    "rdd2 = spark.sparkContext.parallelize(data2).union(rdd) \n",
    "print(rdd2.collect())\n",
    "\n",
    "# union ve distinct fonksiyonlarını birlikte kullanma\n",
    "# rdd2 ve rdd birleştirilip tekrar eden elemanlar silinir\n",
    "rdd3 = spark.sparkContext.parallelize(data2).union(rdd).distinct() \n",
    "print(rdd3.collect())\n",
    "\n",
    "\n",
    "# RDD'lerde çeşitli dönüşümler ve aksiyonlar\n",
    "# map fonksiyonu ile rdd elemanlarını 2 ile çarpma\n",
    "rdd4 = rdd.map(lambda x: x * 2)\n",
    "print(f\"rdd4: {rdd4.collect()}\")\n",
    "\n",
    "# filter fonksiyonu ile rdd elemanlarını filtreleme\n",
    "rdd5 = rdd.filter(lambda x: x % 2 == 0)\n",
    "print(f\"rdd5: {rdd5.collect()}\")\n",
    "\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "654b1b88-3d71-433d-9ca0-f24aecb11e24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[I 2023-08-19 11:05:28.556 ServerApp] nbdime | extension was successfully loaded.', '[I 2023-08-19 11:05:28.572 ServerApp] notebook | extension was successfully loaded.', '[I 2023-08-19 11:05:28.573 ServerApp] Serving notebooks from local directory: /home/jovyan', '[I 2023-08-19 11:05:28.573 ServerApp] Jupyter Server 2.7.0 is running at:', '[I 2023-08-19 11:05:28.573 ServerApp] http://2280f2ea7fc6:8888/lab?token=ead22ed58384365cf07c6bbd850c3fc81eafcc99f66e40be', '[I 2023-08-19 11:05:28.573 ServerApp]  Spark   http://127.0.0.1:8888/lab?token=ead22ed58384365cf07c6bbd850c3fc81eafcc99f66e40be', '[I 2023-08-19 11:05:28.573 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).', '[C 2023-08-19 11:05:28.602 ServerApp]sadsadSpark sdfsd fsdf']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"ParallelizeExample\").getOrCreate()\n",
    "\n",
    "read_txt = spark.sparkContext.textFile(\"dbfs:/FileStore/tables/metin_dosyasi.txt\")\n",
    "print(read_txt.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "076813cd-9667-4858-8901-a6525ad95151",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[I 2023-08-19 11:05:28.556 ServerApp] nbdime | extension was successfully loaded.', '[I 2023-08-19 11:05:28.572 ServerApp] notebook | extension was successfully loaded.', '[I 2023-08-19 11:05:28.573 ServerApp] Serving notebooks from local directory: /home/jovyan', '[I 2023-08-19 11:05:28.573 ServerApp] Jupyter Server 2.7.0 is running at:', '[I 2023-08-19 11:05:28.573 ServerApp] http://2280f2ea7fc6:8888/lab?token=ead22ed58384365cf07c6bbd850c3fc81eafcc99f66e40be', '[I 2023-08-19 11:05:28.573 ServerApp]  Spark   http://127.0.0.1:8888/lab?token=ead22ed58384365cf07c6bbd850c3fc81eafcc99f66e40be', '[I 2023-08-19 11:05:28.573 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).', '[C 2023-08-19 11:05:28.602 ServerApp]sadsadSpark sdfsd fsdf']\n*************************\n['[I 2023-08-19 11:05:28.556 ServerApp] nbdime | extension was successfully loaded.', '[I 2023-08-19 11:05:28.572 ServerApp] notebook | extension was successfully loaded.']\n*************************\n[I 2023-08-19 11:05:28.556 ServerApp] nbdime | extension was successfully loaded.\n*************************\n8\n*************************\n['[I 2023-08-19 11:05:28.573 ServerApp] http://2280f2ea7fc6:8888/lab?token=ead22ed58384365cf07c6bbd850c3fc81eafcc99f66e40be', '[I 2023-08-19 11:05:28.573 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).']\n*************************\n['[I 2023-08-19 11:05:28.573 ServerApp] Serving notebooks from local directory: /home/jovyan', '[I 2023-08-19 11:05:28.573 ServerApp] Jupyter Server 2.7.0 is running at:']\n"
     ]
    }
   ],
   "source": [
    "# ekrana yazdırma yolları\n",
    "print(read_txt.collect()) # tüm satırları listeler\n",
    "print(\"*************************\")\n",
    "print(read_txt.take(2)) # ilk iki satırı listeler\n",
    "print(\"*************************\")\n",
    "print(read_txt.first()) # ilk satırı listeler\n",
    "print(\"*************************\")\n",
    "print(read_txt.count()) # satır sayısını verir\n",
    "print(\"*************************\")\n",
    "print(read_txt.top(2)) # son iki satırı listeler\n",
    "print(\"*************************\")\n",
    "print(read_txt.takeSample(False, 2)) # rastgele iki satırı listeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0061af3-7b9d-4185-8993-ea6b455a6bad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[I 2023-08-19 11:05:28.573 ServerApp] Serving notebooks from local directory: /home/jovyan',\n",
       " '[I 2023-08-19 11:05:28.573 ServerApp] Jupyter Server 2.7.0 is running at:',\n",
       " '[I 2023-08-19 11:05:28.573 ServerApp] http://2280f2ea7fc6:8888/lab?token=ead22ed58384365cf07c6bbd850c3fc81eafcc99f66e40be',\n",
       " '[I 2023-08-19 11:05:28.573 ServerApp]  Spark   http://127.0.0.1:8888/lab?token=ead22ed58384365cf07c6bbd850c3fc81eafcc99f66e40be',\n",
       " '[I 2023-08-19 11:05:28.556 ServerApp] nbdime | extension was successfully loaded.',\n",
       " '[I 2023-08-19 11:05:28.572 ServerApp] notebook | extension was successfully loaded.',\n",
       " '[I 2023-08-19 11:05:28.573 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).',\n",
       " '[C 2023-08-19 11:05:28.602 ServerApp]sadsadSpark sdfsd fsdf']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veriye distinct uygulama\n",
    "distinct_txt = read_txt.distinct()\n",
    "distinct_txt.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba100b4f-6989-490d-b17f-64be142c5bfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[112] at RDD at PythonRDD.scala:60\n[81, 83, 90, 73, 121, 127, 127, 59]\n"
     ]
    }
   ],
   "source": [
    "# txt dosyasındaki satırların uzunluklarını bulma\n",
    "txt_len = read_txt.map(lambda line: len(line))\n",
    "print(txt_len)\n",
    "print(txt_len.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db71dae5-1635-4e89-9ef2-543cc90b7b3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[113] at RDD at PythonRDD.scala:60\n[81, 83, 90, 73, 121, 127, 127, 59]\n"
     ]
    }
   ],
   "source": [
    "def len_line(line):\n",
    "    return len(line)\n",
    "    \n",
    "txt_len1 = read_txt.map(len_line)\n",
    "print(txt_len1)\n",
    "print(txt_len1.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f926853e-0a15-49a6-90db-04e5f518badf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[I 2023-08-19 11:05:28.573 ServerApp]  Spark   http://127.0.0.1:8888/lab?token=ead22ed58384365cf07c6bbd850c3fc81eafcc99f66e40be',\n",
       " '[C 2023-08-19 11:05:28.602 ServerApp]sadsadSpark sdfsd fsdf']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Spark\" kelimesini içeren satırları filtreleme\n",
    "spark_lines = read_txt.filter(lambda line: \"Spark\" in line)\n",
    "spark_lines.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c37855d6-efaf-47b9-beb2-251c5b74cd19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[I 2023-08-19 11:05:28.573 ServerApp]  Spark   http://127.0.0.1:8888/lab?token=ead22ed58384365cf07c6bbd850c3fc81eafcc99f66e40be', '[C 2023-08-19 11:05:28.602 ServerApp]sadsadSpark sdfsd fsdf']\n"
     ]
    }
   ],
   "source": [
    "def spark_filter(line):\n",
    "    return \"Spark\" in line\n",
    "    \n",
    "spark_lines = read_txt.filter(spark_filter)\n",
    "print(spark_lines.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f473c31c-f01d-43c3-b377-b62905df0e73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "PySparkRDD",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
