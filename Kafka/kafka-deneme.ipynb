{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in c:\\python311\\lib\\site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka Producer\n",
    "- Kafka topiğine mesaj gönderen herhangi bir uygulama Kafka Producer olarak adlandırılır.\n",
    "- Kafka Producer'lar, Kafka Broker'lar ile iletişim kurarak mesajları Kafka Cluster'a gönderir.\n",
    "- Kafka Producer'lar, mesajları belirli bir Kafka topic'ine gönderir.\n",
    "- Kafka Producer'lar, mesajları belirli bir Kafka partition'ına gönderir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers='34.44.147.207:9092') # kafkanın ip adresi ve port numarası\n",
    "producer.send('test', 'Hello, Worldi!'.encode('utf-8'))# test isimli topic e mesaj gönderiyoruz . encode utf-8 ile mesajı byte a çeviriyoruz\n",
    "\n",
    "# flush() metodu producer ın bufferını boşaltır ve mesajı gönderir\n",
    "# bufferın anlamı producer ın mesajları topladığı yerdir.\n",
    "producer.flush()# mesajı gönderiyoruz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers='34.44.147.207:9092') # kafkanın ip adresi ve port numarası\n",
    "producer.send('test', b'Hello, Worldi!')# test isimli topic e mesaj gönderiyoruz . encode utf-8 ile mesajı byte a çeviriyoruz\n",
    "\n",
    "# flush() metodu producer ın bufferını boşaltır ve mesajı gönderir\n",
    "# bufferın anlamı producer ın mesajları topladığı yerdir.\n",
    "producer.flush()# mesajı gönderiyoruz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kafka.producer.future.FutureRecordMetadata at 0x1868c893550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json\n",
    "\n",
    "def json_serializer(data):\n",
    "    return json.dumps(data).encode('utf-8')\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers='34.44.147.207:9092',\n",
    "                        value_serializer=lambda v: json.dumps(v).encode('utf-8'),\n",
    "                        key_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
    "\n",
    "producer.send(\n",
    "    topic='test',\n",
    "    key= 'deneme',\n",
    "    value= {'isim':'ali', 'soyisim':'veli'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka Consumer\n",
    "- Kafka topiğinden mesaj okuyan herhangi bir uygulama Kafka Consumer olarak adlandırılır.\n",
    "- Kafka Consumer'lar, Kafka Broker'lar ile iletişim kurarak mesajları Kafka Cluster'dan okur.\n",
    "- Kafka Consumer'lar, mesajları belirli bir Kafka topic'inden okur.\n",
    "- Kafka Consumer'lar, mesajları belirli bir Kafka partition'ından okur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer('test',bootstrap_servers='34.44.147.207:9092')\n",
    "\n",
    "for message in consumer:\n",
    "    print(message.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "\n",
    "def json_deserializer(v):\n",
    "    if v is None:\n",
    "        return None\n",
    "    return json.loads(v)\n",
    "\n",
    "\n",
    "consumer = KafkaConsumer('test',bootstrap_servers='34.44.147.207:9092',\n",
    "                        value_deserializer=lambda v: json.loads(v),\n",
    "                        key_deserializer=lambda v: json.loads(v))\n",
    "\n",
    "for message in consumer:\n",
    "    print(message.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "consumer = KafkaConsumer('test',bootstrap_servers='34.44.147.207:9092',\n",
    "                        value_deserializer=lambda v: json.loads(v),\n",
    "                        key_deserializer=lambda v: json.loads(v),\n",
    "                        auto_offset_reset='earliest', # en eski mesajdan itibaren okuma yapar default latest tir\n",
    "                        group_id='my-group2'\n",
    "                        ) \n",
    "\n",
    "\n",
    "for message in consumer:\n",
    "    print(message.value)\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'City': 'Paris', 'Region': 'Ile-de-France', 'Country': 'France', 'AirQuality': '3.402.439.024', 'WaterPollution': '4.312.169.312', 'ph': nan, 'Hardness': '1.501.749.233.951.360', 'Solids': '27.331.361.961.927.700', 'Chloramines': '6.838.223.470.687.500', 'Sulfate': '29.941.578.134.685.800', 'Conductivity': '37.976.183.482.577.200', 'Organic_carbon': '19.370.807.181.232.100', 'Trihalomethanes': '765.099.955.279.583', 'Turbidity': '4.413.974.182.974.900', 'Potability': 0}\n",
      "{'City': 'Boston', 'Region': 'Massachusetts', 'Country': 'United States of America', 'AirQuality': '7.823.529.412', 'WaterPollution': '3.291.139.241', 'ph': '749.623.220.797.336', 'Hardness': '20.534.498.215.818.500', 'Solids': '2.838.800.488.673.690', 'Chloramines': '5.072.557.773.840.630', 'Sulfate': nan, 'Conductivity': '4.446.453.523.327.060', 'Organic_carbon': '13.228.311.099.224.500', 'Trihalomethanes': '7.030.021.264.692.430', 'Turbidity': '4.777.382.337.225.370', 'Potability': 0}\n",
      "{'City': 'Toronto', 'Region': 'Ontario', 'Country': 'Canada', 'AirQuality': '6.553.468.208', 'WaterPollution': '377.994.012', 'ph': '6.347.271.760.539.310', 'Hardness': '18.673.288.066.057.600', 'Solids': '4.106.523.476.453.930', 'Chloramines': '9.629.596.276.480.580', 'Sulfate': '3.644.876.872.467.600', 'Conductivity': '516.743.281.893.657', 'Organic_carbon': '11.539.781.191.539.400', 'Trihalomethanes': '7.507.161.728.663.770', 'Turbidity': '4.376.348.290.691.890', 'Potability': 0}\n",
      "{'City': 'Sao Paulo', 'Region': 'Sao Paulo', 'Country': 'Brazil', 'AirQuality': '2.405.660.377', 'WaterPollution': '7.371.794.872', 'ph': '7.051.785.800.016.840', 'Hardness': '21.104.940.606.054.500', 'Solids': '30.980.600.786.788.800', 'Chloramines': '10.094.796.011.661.400', 'Sulfate': nan, 'Conductivity': '3.151.412.672.443.020', 'Organic_carbon': '2.039.702.184.072.240', 'Trihalomethanes': '5.665.160.378.979.330', 'Turbidity': '4.268.428.857.506.180', 'Potability': 0}\n",
      "{'City': 'Vilnius', 'Region': nan, 'Country': 'Lithuania', 'AirQuality': '7.724.719.101', 'WaterPollution': '2.058.823.529', 'ph': '9.181.560.007.151.530', 'Hardness': '27.381.380.665.980.000', 'Solids': '2.404.132.628.006.120', 'Chloramines': '6.904.989.726.470.090', 'Sulfate': '3.983.505.168.222.770', 'Conductivity': '4.779.746.418.621.770', 'Organic_carbon': '13.387.340.780.225.500', 'Trihalomethanes': '714.573.622.129.516', 'Turbidity': '4.503.660.796.179.120', 'Potability': 0}\n",
      "{'City': 'Monaco', 'Region': nan, 'Country': 'Monaco', 'AirQuality': '2.878.787.879', 'WaterPollution': '6.136.363.636', 'ph': '8.975.464.347.533.960', 'Hardness': '27.935.716.677.009.200', 'Solids': '19.460.398.131.232.100', 'Chloramines': '6.204.320.858.892.470', 'Sulfate': nan, 'Conductivity': '43.144.398.999.034.800', 'Organic_carbon': '1.288.875.905.430.390', 'Trihalomethanes': '6.382.123.709.666.390', 'Turbidity': '24.360.855.903.052.700', 'Potability': 0}\n",
      "{'City': 'Brussels', 'Region': nan, 'Country': 'Belgium', 'AirQuality': '3.581.081.081', 'WaterPollution': '4.476.190.476', 'ph': '7.371.050.302.429.530', 'Hardness': '21.449.661.045.715.600', 'Solids': '25.630.320.036.999.700', 'Chloramines': '4.432.669.290.372.120', 'Sulfate': '33.575.443.859.606.500', 'Conductivity': '46.991.455.147.923.500', 'Organic_carbon': '12.509.163.940.498.600', 'Trihalomethanes': '6.279.727.715.266.120', 'Turbidity': '25.602.991.476.149.100', 'Potability': 0}\n",
      "{'City': 'Poznan', 'Region': 'Greater Poland Voivodeship', 'Country': 'Poland', 'AirQuality': '3.307.692.308', 'WaterPollution': '5.042.372.881', 'ph': nan, 'Hardness': '22.743.504.835.115.500', 'Solids': '2.230.556.741.374.140', 'Chloramines': '10.333.917.888.218.600', 'Sulfate': nan, 'Conductivity': '5.548.200.864.605.430', 'Organic_carbon': '1.633.169.328.269.440', 'Trihalomethanes': '45.382.815.177.870.900', 'Turbidity': '413.342.264.357.917', 'Potability': 0}\n",
      "{'City': 'Tashkent', 'Region': nan, 'Country': 'Uzbekistan', 'AirQuality': '564.516.129', 'WaterPollution': '4.916.666.667', 'ph': '6.660.212.026.118.100', 'Hardness': '16.828.374.685.651.800', 'Solids': '30.944.363.591.242.600', 'Chloramines': '5.858.769.130.547.580', 'Sulfate': '31.093.085.831.787.800', 'Conductivity': '5.236.712.975.009.440', 'Organic_carbon': '1.788.423.519.296.480', 'Trihalomethanes': '770.423.180.517.003', 'Turbidity': '37.497.012.410.996.100', 'Potability': 0}\n",
      "{'City': 'Warsaw', 'Region': 'Masovian Voivodeship', 'Country': 'Poland', 'AirQuality': '2.727.272.727', 'WaterPollution': '3.601.485.149', 'ph': nan, 'Hardness': '21.597.785.868.806.700', 'Solids': '17.107.224.225.827.600', 'Chloramines': '5.607.060.453.087.120', 'Sulfate': '326.943.977.743.867', 'Conductivity': '43.625.619.397.264.900', 'Organic_carbon': '14.189.062.206.123.700', 'Trihalomethanes': '5.985.547.582.615.380', 'Turbidity': '5.459.250.956.028.730', 'Potability': 0}\n",
      "{'City': 'Modena', 'Region': 'Emilia-Romagna', 'Country': 'Italy', 'AirQuality': '390.625', 'WaterPollution': '50', 'ph': '3.902.475.685.915.090', 'Hardness': '1.969.032.467.083.200', 'Solids': '21.167.500.098.968.700', 'Chloramines': '6.996.311.586.298.760', 'Sulfate': nan, 'Conductivity': '44.447.888.250.689.700', 'Organic_carbon': '16.609.033.155.789.900', 'Trihalomethanes': '901.816.758.847.452', 'Turbidity': '4.528.522.696.326.910', 'Potability': 0}\n",
      "{'City': 'Tours', 'Region': nan, 'Country': 'France', 'AirQuality': '84.375', 'WaterPollution': '6.25', 'ph': '5.400.301.780.729.460', 'Hardness': '14.073.906.225.113.900', 'Solids': '17.266.593.421.923.000', 'Chloramines': '10.056.852.484.033.400', 'Sulfate': '3.283.582.406.986.830', 'Conductivity': '4.728.740.732.754.290', 'Organic_carbon': '11.256.381.166.909.400', 'Trihalomethanes': '569.319.064.457.562', 'Turbidity': '4.824.786.389.767.520', 'Potability': 0}\n",
      "{'City': 'Singapore', 'Region': nan, 'Country': 'Singapore', 'AirQuality': '6.587.837.838', 'WaterPollution': '24.204.947', 'ph': '6.514.415.093.251.670', 'Hardness': '19.876.735.125.945.600', 'Solids': '21.218.702.871.190.100', 'Chloramines': '867.093.691.991.312', 'Sulfate': '3.235.963.490.101.310', 'Conductivity': '4.132.904.500.885.340', 'Organic_carbon': '14.899.999.566.696.900', 'Trihalomethanes': '7.984.784.281.372.550', 'Turbidity': '5.200.885.076.539.750', 'Potability': 0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      6\u001b[0m consumer \u001b[38;5;241m=\u001b[39m KafkaConsumer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeneme1\u001b[39m\u001b[38;5;124m'\u001b[39m,bootstrap_servers\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m34.44.147.207:9092\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m                         value_deserializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m v: json\u001b[38;5;241m.\u001b[39mloads(v),\n\u001b[0;32m      8\u001b[0m                         key_deserializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m v: json\u001b[38;5;241m.\u001b[39mloads(v),\n\u001b[0;32m      9\u001b[0m                         auto_offset_reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# en eski mesajdan itibaren okuma yapar default latest tir\u001b[39;00m\n\u001b[0;32m     10\u001b[0m                         group_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy-group1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m                         ) \n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconsumer\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPotability\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:1193\u001b[0m, in \u001b[0;36mKafkaConsumer.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_v1()\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:1201\u001b[0m, in \u001b[0;36mKafkaConsumer.next_v2\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_generator_v2()\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator)\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:1116\u001b[0m, in \u001b[0;36mKafkaConsumer._message_generator_v2\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_message_generator_v2\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1115\u001b[0m     timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consumer_timeout \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime())\n\u001b[1;32m-> 1116\u001b[0m     record_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tp, records \u001b[38;5;129;01min\u001b[39;00m six\u001b[38;5;241m.\u001b[39miteritems(record_map):\n\u001b[0;32m   1118\u001b[0m         \u001b[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m         \u001b[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[0;32m   1120\u001b[0m         \u001b[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m records:\n\u001b[0;32m   1122\u001b[0m             \u001b[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m             \u001b[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m             \u001b[38;5;66;03m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m             \u001b[38;5;66;03m# via self._iterator = None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:655\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[1;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[0;32m    653\u001b[0m remaining \u001b[38;5;241m=\u001b[39m timeout_ms\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 655\u001b[0m     records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[0;32m    657\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m records\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:702\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[1;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpoll(timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    701\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout_ms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mtime_to_next_poll() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m--> 702\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mneed_rejoin():\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kafka\\client_async.py:602\u001b[0m, in \u001b[0;36mKafkaClient.poll\u001b[1;34m(self, timeout_ms, future)\u001b[0m\n\u001b[0;32m    599\u001b[0m             timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretry_backoff_ms\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    600\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, timeout)  \u001b[38;5;66;03m# avoid negative timeouts\u001b[39;00m\n\u001b[1;32m--> 602\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# if handlers need to acquire locks\u001b[39;00m\n\u001b[0;32m    606\u001b[0m responses\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_pending_completed_requests())\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\kafka\\client_async.py:634\u001b[0m, in \u001b[0;36mKafkaClient._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_send_sockets()\n\u001b[0;32m    633\u001b[0m start_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 634\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m end_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sensors:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\selectors.py:323\u001b[0m, in \u001b[0;36mSelectSelector.select\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    321\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m     r, w, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\selectors.py:314\u001b[0m, in \u001b[0;36mSelectSelector._select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 314\u001b[0m     r, w, x \u001b[38;5;241m=\u001b[39m select\u001b[38;5;241m.\u001b[39mselect(r, w, w, timeout)\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w \u001b[38;5;241m+\u001b[39m x, []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "consumer = KafkaConsumer('deneme1',bootstrap_servers='34.44.147.207:9092',\n",
    "                        value_deserializer=lambda v: json.loads(v),\n",
    "                        key_deserializer=lambda v: json.loads(v),\n",
    "                        auto_offset_reset='latest', # en eski mesajdan itibaren okuma yapar default latest tir\n",
    "                        group_id='my-group1'\n",
    "                        ) \n",
    "\n",
    "\n",
    "for message in consumer:\n",
    "    val = message.value\n",
    "    if val[\"Potability\"] == 0:\n",
    "        print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     14\u001b[0m     producer\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m     15\u001b[0m         topic\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m         value\u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mto_dict())\n\u001b[1;32m---> 18\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers='34.44.147.207:9092',\n",
    "                        value_serializer=lambda v: json.dumps(v).encode('utf-8'),\n",
    "                        key_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
    "\n",
    "df = pd.read_csv('water_quality.csv',sep=';')\n",
    "\n",
    "for i,row in df.iterrows():\n",
    "    producer.send(\n",
    "        topic='test1',\n",
    "        value= row.to_dict())\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka Admin Client\n",
    "- Kafka Admin Client, Kafka Cluster'ı yönetmek için kullanılan bir Java API'sidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test4', 'test5', '__consumer_offsets']\n",
      "[DescribeConfigsResponse_v2(throttle_time_ms=0, resources=[(error_code=0, error_message='', resource_type=2, resource_name='test5', config_entries=[(config_names='compression.type', config_value='producer', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='leader.replication.throttled.replicas', config_value='', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='min.insync.replicas', config_value='1', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='message.downconversion.enable', config_value='true', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='segment.jitter.ms', config_value='0', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='cleanup.policy', config_value='delete', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='flush.ms', config_value='9223372036854775807', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='follower.replication.throttled.replicas', config_value='', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='segment.bytes', config_value='1073741824', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='retention.ms', config_value='604800000', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='flush.messages', config_value='9223372036854775807', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='message.format.version', config_value='3.0-IV1', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='max.compaction.lag.ms', config_value='9223372036854775807', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='file.delete.delay.ms', config_value='60000', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='max.message.bytes', config_value='1048588', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='min.compaction.lag.ms', config_value='0', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='message.timestamp.type', config_value='CreateTime', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='preallocate', config_value='false', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='index.interval.bytes', config_value='4096', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='min.cleanable.dirty.ratio', config_value='0.5', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='unclean.leader.election.enable', config_value='false', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='retention.bytes', config_value='-1', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='delete.retention.ms', config_value='86400000', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='segment.ms', config_value='604800000', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='message.timestamp.difference.max.ms', config_value='9223372036854775807', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[]), (config_names='segment.index.bytes', config_value='10485760', read_only=False, config_source=5, is_sensitive=False, config_synonyms=[])])])]\n"
     ]
    }
   ],
   "source": [
    "# KafkaAdminClient -> Kafka cluster yönetimi için kullanılır\n",
    "# NewTopic -> Yeni topic oluşturmak için kullanılır\n",
    "# NewPartitions -> Varolan topic'e yeni partition eklemek için kullanılır\n",
    "# ConfigResource -> Topic configlerini görüntülemek için kullanılır\n",
    "# ConfigResourceType -> ConfigResource tipini belirtmek için kullanılır\n",
    "from kafka.admin import KafkaAdminClient, NewTopic, NewPartitions, ConfigResource, ConfigResourceType\n",
    "\n",
    "# bootstrap_servers -> Kafka broker'ın adresi ve port numarası\n",
    "# client_id -> KafkaAdminClient'in client id'si\n",
    "admin_client = KafkaAdminClient(bootstrap_servers='34.44.147.207:9092', \n",
    "                                client_id='test' \n",
    "                                )\n",
    "\n",
    "# topic listeleme\n",
    "topic_list = admin_client.list_topics()\n",
    "print(topic_list)\n",
    "\n",
    "\n",
    "# # topic oluşturma\n",
    "# # List içerisine NewTopic objesi ekleyerek birden fazla topic tek seferde oluşturabiliriz\n",
    "# yeni_topic = [\n",
    "#     NewTopic(name=\"test2\", num_partitions=3, replication_factor=1),\n",
    "#     NewTopic(name=\"test3\", num_partitions=3, replication_factor=1),\n",
    "#     NewTopic(name=\"test4\", num_partitions=3, replication_factor=1),\n",
    "#     NewTopic(name=\"test5\", num_partitions=3, replication_factor=1)\n",
    "# ]\n",
    "\n",
    "# try:\n",
    "#     admin_client.create_topics(new_topics=yeni_topic, validate_only=False)\n",
    "#     print(\"topic oluşturuldu\")  \n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "\n",
    "\n",
    "# # topic silme\n",
    "# try:\n",
    "#     admin_client.delete_topics(topics=[\"test2\", \"test3\"], timeout_ms=60000)\n",
    "#     print(\"topic silindi\")\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "\n",
    "# # topic partition arttırma\n",
    "# try:\n",
    "#     admin_client.create_partitions(\n",
    "#         {\n",
    "#             \"test4\": NewPartitions(total_count=6),\n",
    "#             \"test5\": NewPartitions(total_count=6)\n",
    "#         }\n",
    "#     )\n",
    "#     print(\"partition arttırıldı\")\n",
    "# except Exception as e:\n",
    "#     print(e)    \n",
    "\n",
    "# # topic config görüntüleme\n",
    "# config = admin_client.describe_configs([ConfigResource(ConfigResourceType.TOPIC, \"test5\")])\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


